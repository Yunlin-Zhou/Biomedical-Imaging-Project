{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import argparse\nimport os\nimport random\nimport logging\nimport numpy as np\nimport time\nimport torch\nimport torch.backends.cudnn as cudnn\nimport torch.optim\nimport sys\n!pip install MedPy\nfrom medpy.metric.binary import hd\n\nimport torch.distributed as dist\nimport torch.nn as nn\nimport matplotlib.pyplot as plt\nfrom torch.utils.data import Dataset, DataLoader\nimport nibabel as nib","metadata":{"execution":{"iopub.status.busy":"2023-05-10T05:41:38.181180Z","iopub.execute_input":"2023-05-10T05:41:38.182130Z","iopub.status.idle":"2023-05-10T05:41:59.851599Z","shell.execute_reply.started":"2023-05-10T05:41:38.182084Z","shell.execute_reply":"2023-05-10T05:41:59.850465Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"Collecting MedPy\n  Downloading MedPy-0.4.0.tar.gz (151 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m151.8/151.8 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: scipy>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from MedPy) (1.9.3)\nRequirement already satisfied: numpy>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from MedPy) (1.23.5)\nRequirement already satisfied: SimpleITK>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from MedPy) (2.2.1)\nBuilding wheels for collected packages: MedPy\n  Building wheel for MedPy (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for MedPy: filename=MedPy-0.4.0-py3-none-any.whl size=214963 sha256=f415fdb89384f94a4b5792e59423b87a80061ddac82c097b605e1a1b00d8c014\n  Stored in directory: /root/.cache/pip/wheels/d4/32/c7/6380ab2edb8cca018d39a0f1d43250fd9791922c963117de46\nSuccessfully built MedPy\nInstalling collected packages: MedPy\nSuccessfully installed MedPy-0.4.0\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"!git clone https://github.com/raovish6/TABS","metadata":{"execution":{"iopub.status.busy":"2023-05-10T05:32:52.902357Z","iopub.execute_input":"2023-05-10T05:32:52.908541Z","iopub.status.idle":"2023-05-10T05:32:54.889543Z","shell.execute_reply.started":"2023-05-10T05:32:52.908497Z","shell.execute_reply":"2023-05-10T05:32:54.888353Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Cloning into 'TABS'...\nremote: Enumerating objects: 77, done.\u001b[K\nremote: Counting objects: 100% (77/77), done.\u001b[K\nremote: Compressing objects: 100% (64/64), done.\u001b[K\nremote: Total 77 (delta 31), reused 28 (delta 9), pack-reused 0\u001b[K\nUnpacking objects: 100% (77/77), 35.08 KiB | 1.30 MiB/s, done.\n","output_type":"stream"}]},{"cell_type":"code","source":"sys.path.append('/kaggle/working/TABS') ","metadata":{"execution":{"iopub.status.busy":"2023-05-10T05:32:57.584813Z","iopub.execute_input":"2023-05-10T05:32:57.586036Z","iopub.status.idle":"2023-05-10T05:32:57.591350Z","shell.execute_reply.started":"2023-05-10T05:32:57.585990Z","shell.execute_reply":"2023-05-10T05:32:57.590062Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"from Models.TABS_Model import TABS","metadata":{"execution":{"iopub.status.busy":"2023-05-10T05:33:00.150704Z","iopub.execute_input":"2023-05-10T05:33:00.151082Z","iopub.status.idle":"2023-05-10T05:33:00.164310Z","shell.execute_reply.started":"2023-05-10T05:33:00.151047Z","shell.execute_reply":"2023-05-10T05:33:00.163406Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"!pip install gdown\n!gdown https://drive.google.com/uc?id=1Du6N8hr4lcRCjwSYuwLsepzWVXPmdjEr","metadata":{"execution":{"iopub.status.busy":"2023-05-10T05:33:52.025640Z","iopub.execute_input":"2023-05-10T05:33:52.026033Z","iopub.status.idle":"2023-05-10T05:34:06.849926Z","shell.execute_reply.started":"2023-05-10T05:33:52.025999Z","shell.execute_reply":"2023-05-10T05:34:06.848732Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Requirement already satisfied: gdown in /opt/conda/lib/python3.10/site-packages (4.7.1)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from gdown) (4.64.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from gdown) (3.11.0)\nRequirement already satisfied: requests[socks] in /opt/conda/lib/python3.10/site-packages (from gdown) (2.28.2)\nRequirement already satisfied: beautifulsoup4 in /opt/conda/lib/python3.10/site-packages (from gdown) (4.12.2)\nRequirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from gdown) (1.16.0)\nRequirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.10/site-packages (from beautifulsoup4->gdown) (2.4)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (3.4)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (2022.12.7)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (2.1.1)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (1.26.15)\nRequirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (1.7.1)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mDownloading...\nFrom (uriginal): https://drive.google.com/uc?id=1Du6N8hr4lcRCjwSYuwLsepzWVXPmdjEr\nFrom (redirected): https://drive.google.com/uc?id=1Du6N8hr4lcRCjwSYuwLsepzWVXPmdjEr&confirm=t&uuid=305072b4-1e59-40b9-a398-5412ed0c40c8\nTo: /kaggle/working/best_model_TABS.pth\n100%|█████████████████████████████████████████| 285M/285M [00:01<00:00, 211MB/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"class CTScanDataset(Dataset):\n    def __init__(self, ct_scan_data, mask_data, cube_size=(80, 80, 80), channels=1):\n        self.ct_scan = ct_scan_data\n        self.mask = mask_data\n        self.cube_size = cube_size\n        self.channels = channels\n\n    def __len__(self):\n        #return len(self.ct_scan)\n        return 120\n\n    def __getitem__(self, idx):\n        # Get random cube of specified size\n        x_start = np.random.randint(0, self.ct_scan.shape[1] - self.cube_size[0])\n        y_start = np.random.randint(0, self.ct_scan.shape[2] - self.cube_size[1])\n        z_start = np.random.randint(0, self.ct_scan.shape[0] - self.cube_size[2])\n        x_end = x_start + self.cube_size[0]\n        y_end = y_start + self.cube_size[1]\n        z_end = z_start + self.cube_size[2]\n        ct_cube = self.ct_scan[z_start:z_end, x_start:x_end, y_start:y_end]\n        mask_cube = self.mask[z_start:z_end, x_start:x_end, y_start:y_end]\n\n        # Add channel dimension\n        if self.channels == 1:\n            ct_cube = torch.unsqueeze(torch.from_numpy(ct_cube).float(), 0)\n            mask_cube = np.repeat(mask_cube[np.newaxis,:,:,:], 5, axis=0)\n            mask_cube = torch.from_numpy(mask_cube).float()\n            \n        else:\n            ct_cube = torch.from_numpy(ct_cube).float()\n            mask_cube = torch.from_numpy(mask_cube).float()\n            \n\n        return ct_cube, mask_cube","metadata":{"execution":{"iopub.status.busy":"2023-05-10T05:34:58.501979Z","iopub.execute_input":"2023-05-10T05:34:58.502371Z","iopub.status.idle":"2023-05-10T05:34:58.512691Z","shell.execute_reply.started":"2023-05-10T05:34:58.502341Z","shell.execute_reply":"2023-05-10T05:34:58.511616Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# Load the raw CT scan\nct_scan_1R = nib.load('/kaggle/input/micro-ct-scans-of-human-cochlea-normalized/normalized_ct_1R.nii')\n\n# Load the corresponding mask\nmask_1R = nib.load('/kaggle/input/micro-ct-scans-of-human-cochlea-normalized/normalized_mask_1R.nii')\n\n# Get the CT scan data\nct_scan_1R_data = ct_scan_1R.get_fdata()\n\n# Get the mask data\nmask_1R_data = mask_1R.get_fdata()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset_train = CTScanDataset(ct_scan_1R_data, mask_1R_data, cube_size=(80, 80, 80), channels=1)\ndataloader_train = DataLoader(dataset_train, batch_size=3, shuffle=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Load the raw CT scan\nct_scan_2R = nib.load('/kaggle/input/micro-ct-scans-of-human-cochlea-normalized/normalized_ct_2R.nii')\n\n# Load the corresponding mask\nmask_2R = nib.load('/kaggle/input/micro-ct-scans-of-human-cochlea-normalized/normalized_mask_2R.nii')\n\n# Get the CT scan data\nct_scan_2R_data = ct_scan_2R.get_fdata()\n\n# Get the mask data\nmask_2R_data = mask_2R.get_fdata()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset_val = CTScanDataset(ct_scan_2R_data, mask_2R_data, cube_size=(80, 80, 80), channels=1)\ndataloader_val = DataLoader(dataset_val, batch_size=3, shuffle=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Load the raw CT scan\nct_scan_5R = nib.load('/kaggle/input/micro-ct-scans-of-human-cochlea-normalized-test/normalized_ct_5R.nii')\n\n# Load the corresponding mask\nmask_5R = nib.load('/kaggle/input/micro-ct-scans-of-human-cochlea-normalized-test/normalized_mask_5R.nii')\n\n# Get the CT scan data\nct_scan_5R_data = ct_scan_5R.get_fdata()\n\n# Get the mask data\nmask_5R_data = mask_5R.get_fdata()","metadata":{"execution":{"iopub.status.busy":"2023-05-10T05:35:04.055642Z","iopub.execute_input":"2023-05-10T05:35:04.056007Z","iopub.status.idle":"2023-05-10T05:35:24.597749Z","shell.execute_reply.started":"2023-05-10T05:35:04.055979Z","shell.execute_reply":"2023-05-10T05:35:24.596790Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"x = torch.tensor(mask_5R_data)\n\n# check if tensor is binary\nis_binary = ((x == 0) | (x == 1)).all()\n\nif is_binary:\n    print(\"The tensor is binary.\")\nelse:\n    print(\"The tensor is not binary.\")","metadata":{"execution":{"iopub.status.busy":"2023-05-10T06:36:39.803650Z","iopub.execute_input":"2023-05-10T06:36:39.804041Z","iopub.status.idle":"2023-05-10T06:36:39.834945Z","shell.execute_reply.started":"2023-05-10T06:36:39.804012Z","shell.execute_reply":"2023-05-10T06:36:39.833893Z"},"trusted":true},"execution_count":44,"outputs":[{"name":"stdout","text":"The tensor is not binary.\n","output_type":"stream"}]},{"cell_type":"code","source":"num_rows_to_view = 5\nfor i in range(num_rows_to_view):\n    print(f\"Rows {i}:\")\n    print(np.squeeze(mask_5R_data[i, :, :]))","metadata":{"execution":{"iopub.status.busy":"2023-05-10T06:40:27.843345Z","iopub.execute_input":"2023-05-10T06:40:27.844441Z","iopub.status.idle":"2023-05-10T06:40:27.853839Z","shell.execute_reply.started":"2023-05-10T06:40:27.844393Z","shell.execute_reply":"2023-05-10T06:40:27.852546Z"},"trusted":true},"execution_count":45,"outputs":[{"name":"stdout","text":"Rows 0:\n[[-1.0062024 -1.0062024 -1.0062024 ... -1.0062024 -1.0062024 -1.0062024]\n [-1.0062024 -1.0062024 -1.0062024 ... -1.0062024 -1.0062024 -1.0062024]\n [-1.0062024 -1.0062024 -1.0062024 ... -1.0062024 -1.0062024 -1.0062024]\n ...\n [-1.0062024 -1.0062024 -1.0062024 ... -1.0062024 -1.0062024 -1.0062024]\n [-1.0062024 -1.0062024 -1.0062024 ... -1.0062024 -1.0062024 -1.0062024]\n [-1.0062024 -1.0062024 -1.0062024 ... -1.0062024 -1.0062024 -1.0062024]]\nRows 1:\n[[ -38.89281136  342.82980826  476.33500174 ... 2196.41711718\n  1818.15240234 1402.15142223]\n [ 343.28083932  179.40622121  407.92862445 ... 1926.85088757\n  1862.20310244 1669.76318392]\n [ 640.96133828  128.13902417  220.60039127 ... 1866.26238197\n  1833.48745835 1892.87321445]\n ...\n [1896.03043187 1817.85171497 2011.34403929 ... 2078.84835446\n  1900.54074246 1771.39551589]\n [2020.36466047 2081.7048845  2289.32951534 ... 1938.87838247\n  1867.16444409 1818.30274603]\n [2410.95755759 2330.82437277 2350.51939568 ... 1839.35086212\n  1818.90412077 1682.39205357]]\nRows 2:\n[[  -5.96754405  395.2997548   512.71817383 ... 2412.31065077\n  2148.30713755 1972.55536821]\n [ 247.8125985   203.16052365  437.0952996  ... 1891.36977759\n  2037.6541844  2177.02278164]\n [ 517.98020285   67.2498312   293.81776652 ... 1766.13348687\n  1890.76840284 2220.02107593]\n ...\n [1983.53045732 1818.75377709 1931.81222922 ... 2039.00727758\n  1937.22460192 2069.22635853]\n [2032.39215538 2096.13787839 2249.0374074  ... 2054.94370833\n  2000.06826282 1907.30620834]\n [2219.87073225 2256.40424803 2485.52802601 ... 2036.45143491\n  1995.8586396  1694.2692048 ]]\nRows 3:\n[[  33.42250177  408.37965551  342.37877721 ... 2514.84504485\n  2472.59846899 2277.6027078 ]\n [ 178.50415909  385.97844625  457.39169726 ... 2071.03048277\n  2036.75212228 2294.59154436]\n [ 394.24734899   91.90619576  183.16481337 ... 1848.97285804\n  1786.58022821 2336.98846391]\n ...\n [2015.85434988 1915.27442372 2011.64472666 ... 1782.37060499\n  1765.08108106 1938.42735142]\n [2172.81315842 2245.57950261 2252.04428113 ... 1953.61206374\n  1932.56394765 1926.39985651]\n [2178.5262185  2199.57433459 2320.14997104 ... 1964.58715284\n  1956.76928115 1755.9101162 ]]\nRows 4:\n[[-169.84216216  122.57630777  148.28507814 ... 2542.50828314\n  2612.11740991 2360.59242266]\n [  99.42338008  485.35562292  536.32213259 ... 2381.33985138\n  2184.99099702 2273.99445933]\n [ 298.17773342  270.21380776  338.16915399 ... 2194.31230557\n  1908.80964521 2139.28651637]\n ...\n [2236.25819406 2081.85522819 2108.91709173 ... 1584.06728271\n  1431.91947213 1672.01833922]\n [2172.51247105 2275.64823988 2280.75992522 ... 1507.99337742\n  1524.08015186 1643.6033825 ]\n [2098.09234631 2241.97125414 2216.41282746 ... 1501.07756785\n  1483.18666917 1349.53113201]]\n","output_type":"stream"}]},{"cell_type":"code","source":"dataset_test = CTScanDataset(ct_scan_5R_data, mask_5R_data , cube_size=(80, 80, 80), channels=1)\ndataloader_test = DataLoader(dataset_test, batch_size=3, shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2023-05-10T05:35:29.450126Z","iopub.execute_input":"2023-05-10T05:35:29.450498Z","iopub.status.idle":"2023-05-10T05:35:29.458657Z","shell.execute_reply.started":"2023-05-10T05:35:29.450470Z","shell.execute_reply":"2023-05-10T05:35:29.457774Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"# Declare variables\ndate = time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime())\nroot = ''\nlr = 0.00001\nweight_decay = 1e-5\namsgrad = True\nseed = 1000\nno_cuda = False\nnum_workers = 4\nbatch_size = 1\nstart_epoch = 0\nend_epoch = 2\ngpu = 0\ngpu_available = '0,1,2'\nload_dir = ''\n\n# Set seed\ntorch.manual_seed(seed)\ntorch.cuda.manual_seed(seed)\nrandom.seed(seed)\nnp.random.seed(seed)","metadata":{"execution":{"iopub.status.busy":"2023-05-10T05:35:32.347251Z","iopub.execute_input":"2023-05-10T05:35:32.347881Z","iopub.status.idle":"2023-05-10T05:35:32.364960Z","shell.execute_reply.started":"2023-05-10T05:35:32.347848Z","shell.execute_reply":"2023-05-10T05:35:32.364040Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"device = \"cuda\" if torch.cuda.is_available() else \"cpu\"","metadata":{"execution":{"iopub.status.busy":"2023-05-10T05:35:34.409374Z","iopub.execute_input":"2023-05-10T05:35:34.409979Z","iopub.status.idle":"2023-05-10T05:35:34.481486Z","shell.execute_reply.started":"2023-05-10T05:35:34.409943Z","shell.execute_reply":"2023-05-10T05:35:34.480301Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"def get_loss(model, criterion, ct_scan, mask, mode):\n\n    if mode == 'val':\n        torch.manual_seed(seed)\n        torch.cuda.manual_seed(seed)\n        random.seed(seed)\n        np.random.seed(seed)\n\n    # Gen model outputs\n    output = model(ct_scan.float())\n\n    # Construct binary brain map to consider loss only within there\n    input_squeezed = torch.squeeze(ct_scan,dim=1)\n    brain_map = (input_squeezed > -1).float()\n    stacked_brain_map = torch.cat([brain_map.unsqueeze(1)]*5, dim=1)\n\n    # Zero out the background of the segmentation output\n    isolated_images = torch.mul(stacked_brain_map, output)\n\n    # Calculate loss over just the brain map\n    loss = criterion(isolated_images, mask)\n    num_brain_voxels = stacked_brain_map.sum()\n    loss = loss / num_brain_voxels\n\n    return loss, isolated_images, stacked_brain_map\n","metadata":{"execution":{"iopub.status.busy":"2023-05-10T05:35:36.532500Z","iopub.execute_input":"2023-05-10T05:35:36.532860Z","iopub.status.idle":"2023-05-10T05:35:36.541486Z","shell.execute_reply.started":"2023-05-10T05:35:36.532832Z","shell.execute_reply":"2023-05-10T05:35:36.540398Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"def tissue_wise_probability_metrics(isolated_image, target, stacked_brain_map):\n    criterion = nn.MSELoss()\n    criterion = criterion.cuda(args.gpu)\n\n    # metrics dict to store metric for each tissue type\n    metrics_list = ['pearson_corr', 'spearman_corr', 'mse']\n    metrics = { i : [] for i in metrics_list }\n\n    # list of flattened tensors being collected and their corresponding dict\n    necessary_flattened_tensors = ['GT_flattened_0', 'GT_flattened_1', 'GT_flattened_2', 'GT_flattened_3', 'GT_flattened_4', 'iso_flattened_0', 'iso_flattened_1', 'iso_flattened_2', 'iso_flattened_3', 'iso_flattened_4']\n    flattened_tensors = { i : {} for i in necessary_flattened_tensors }\n\n    # flattened single channel brain mask (192x192x192 --> flat)\n    mask_flattened = torch.flatten(stacked_brain_map[0])\n\n    # Only save the part of the flattened GT/output that correspond to nonzero values of the brain mask\n    for i in range(0,5):\n        # flatten gt of channel i (each channel corresponds to a tissue type)\n        flattened_tensors['GT_flattened_' + str(i)] = torch.flatten(target[i])\n        # choose only the portion of the flattened gt that correspons to the brain\n        flattened_tensors['GT_flattened_' + str(i)] = flattened_tensors['GT_flattened_' + str(i)][mask_flattened.nonzero(as_tuple=True)]\n        # make this now a numpy array\n        flattened_tensors['GT_flattened_' + str(i)] = flattened_tensors['GT_flattened_' + str(i)].cpu().detach().numpy()\n\n        # repeat for the model output image\n        flattened_tensors['iso_flattened_' + str(i)] = torch.flatten(isolated_image[i])\n        flattened_tensors['iso_flattened_' + str(i)] = flattened_tensors['iso_flattened_' + str(i)][mask_flattened.nonzero(as_tuple=True)]\n        flattened_tensors['iso_flattened_' + str(i)] = flattened_tensors['iso_flattened_' + str(i)].cpu().detach().numpy()\n\n    for i in range(0,5):\n        # get output and gt from dict i just constructed\n        model_output = flattened_tensors['iso_flattened_' + str(i)]\n        GT = flattened_tensors['GT_flattened_' + str(i)]\n\n        # get metrics using the numpy arrays of both (cropped to brain)\n        cur_pcorr = np.corrcoef(model_output, GT)[0][1]\n        cur_scorr = spearmanr(model_output, GT)[0]\n\n        cur_mse = criterion(torch.tensor(model_output).cuda(args.gpu), torch.tensor(GT).cuda(args.gpu))\n\n        metrics['pearson_corr'].append(cur_pcorr)\n        metrics['spearman_corr'].append(cur_scorr)\n        metrics['mse'].append(cur_mse.item())\n\n    return metrics\n","metadata":{"execution":{"iopub.status.busy":"2023-05-10T05:35:38.661906Z","iopub.execute_input":"2023-05-10T05:35:38.662274Z","iopub.status.idle":"2023-05-10T05:35:38.677859Z","shell.execute_reply.started":"2023-05-10T05:35:38.662245Z","shell.execute_reply":"2023-05-10T05:35:38.676839Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"def tissue_wise_map_metrics(isolated_image, target, stacked_brain_map):\n    # metrics dict to store metric for each tissue type\n    metrics_list = ['DICE', 'HD', 'Jaccard']\n    metrics = { i : [] for i in metrics_list }\n\n    # list of flattened tensors (segmentation masks) I'm gonna collect and their corresponding dict\n    necessary_masks_list = ['GT_0', 'GT_1', 'GT_2', 'GT_3', 'GT_4', 'iso_0', 'iso_1', 'iso_2', 'iso_3', 'iso_4']\n    necessary_tensors = { i : {} for i in necessary_masks_list }\n\n    # current output and gt is 3x192x192x192. Basically, each voxel of the brain has 3 probabilities assigned to it for each tissue type. Taking the argmax gives us the most likely tissue type of each voxel (now 1x192x192x192)\n    full_map_model = torch.argmax(isolated_image,0)\n    full_map_GT = torch.argmax(target,0)\n    mask = stacked_brain_map[0]\n    mask_flattened = torch.flatten(stacked_brain_map[0])\n\n    for i in range(0,5):\n        # now that we have the argmax, we can imagine the brain with each voxel having a value of 0,1,2. To get the masks for each tissue type, we save a new tensor corresponding to 1 where the argmax tensor has a value of the given tissue type and 0 otherwise.\n        necessary_tensors['GT_' + str(i)] = (full_map_GT==i).float()\n        necessary_tensors['iso_' + str(i)] = (full_map_model==i).float()\n        if i == 0:\n            # make sure background is 0\n            necessary_tensors['GT_' + str(i)] = torch.mul(necessary_tensors['GT_' + str(i)], mask)\n            necessary_tensors['iso_' + str(i)] = torch.mul(necessary_tensors['iso_' + str(i)], mask)\n\n        # calc HD with the segmentation masks\n        h_dist = hd(necessary_tensors['iso_' + str(i)].cpu().detach().numpy(), necessary_tensors['GT_' + str(i)].cpu().detach().numpy())\n        metrics['HD'].append(h_dist)\n\n        # now make cropped 1d numpy arrays only containing mask values for within the brain for dice calculation\n        necessary_tensors['GT_' + str(i)] = torch.flatten(necessary_tensors['GT_' + str(i)])\n        necessary_tensors['GT_' + str(i)] = necessary_tensors['GT_' + str(i)][mask_flattened.nonzero(as_tuple=True)]\n        necessary_tensors['GT_' + str(i)] = necessary_tensors['GT_' + str(i)].cpu().detach().numpy()\n        necessary_tensors['iso_' + str(i)] = torch.flatten(necessary_tensors['iso_' + str(i)])\n        necessary_tensors['iso_' + str(i)] = necessary_tensors['iso_' + str(i)][mask_flattened.nonzero(as_tuple=True)]\n        necessary_tensors['iso_' + str(i)] = necessary_tensors['iso_' + str(i)].cpu().detach().numpy()\n\n    for i in range(0,5):\n        model_output = necessary_tensors['iso_' + str(i)]\n        GT = necessary_tensors['GT_' + str(i)]\n        # dice formula\n        dice = np.sum(model_output[GT==1])*2.0 / (np.sum(model_output) + np.sum(GT))\n        jaccard = jaccard_score(GT, model_output)\n\n        metrics['DICE'].append(dice)\n        metrics['Jaccard'].append(jaccard)\n\n    return metrics","metadata":{"execution":{"iopub.status.busy":"2023-05-10T06:12:55.197148Z","iopub.execute_input":"2023-05-10T06:12:55.197553Z","iopub.status.idle":"2023-05-10T06:12:55.213311Z","shell.execute_reply.started":"2023-05-10T06:12:55.197523Z","shell.execute_reply":"2023-05-10T06:12:55.212180Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"if __name__ == '__main__':\n\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    random.seed(seed)\n    np.random.seed(seed)\n    \n    model = TABS(img_dim = 80,\n                 output_ch = 5)  # Instantiate an instance of the model's class\n    \n    state_dict = torch.load('/kaggle/working/best_model_TABS.pth')\n    model.load_state_dict(state_dict, strict=False)\n    \n    #checkpoint = torch.load(load_dir, map_location=torch.device(gpu))\n    #model.load_state_dict(checkpoint['state_dict'])  # Load the saved state dictionary\n    model.cuda(gpu)\n    \n    #dataloader_train = DataLoader(dataset_train, batch_size=3, shuffle=True)\n    #dataloader_val = DataLoader(dataset_val, batch_size=3, shuffle=True)\n    \n    criterion = nn.MSELoss(reduction='mean')\n    criterion = criterion.cuda(gpu)\n\n    probability_metrics_list = ['pearson_corr', 'spearman_corr', 'mse']\n    probability_metrics = { i : [] for i in probability_metrics_list }\n    map_metrics_list = ['DICE', 'HD', 'Jaccard']\n    map_metrics = { i : [] for i in map_metrics_list }\n    \n    \n    model.eval()  # Set the model to evaluation mode\n\n\n    with torch.no_grad():\n        val_losses = []\n        test = []\n        val_corr = []\n\n        # Loop through test dataloader here.\n        for i, (ct_scan, mask) in enumerate(dataloader_test):\n\n            dataloader_test = DataLoader(dataset_test, batch_size=3, shuffle=True)\n\n            ct_scan, mask = ct_scan.to(device), mask.to(device)\n\n            loss, isolated_images, stacked_brain_maps  = get_loss(model, criterion, ct_scan, mask, 'val')\n\n            val_losses.append(loss)\n\n            for g in range(0,len(isolated_images)):\n                isolated_image = isolated_images[g]\n                target = mask[g]\n                stacked_brain_map = stacked_brain_maps[g]\n                metrics_maps = tissue_wise_map_metrics(isolated_image, target, stacked_brain_map)\n                metrics =  tissue_wise_probability_metrics(isolated_image, target, stacked_brain_map)\n\n                for metric in probability_metrics_list:\n                    probability_metrics[metric].append(metrics[metric])\n                for metric in map_metrics_list:\n                    map_metrics[metric].append(metrics_maps[metric])\n\n    val_net_loss = sum(val_losses)/len(val_losses)\n\n    overall_pcorr = probability_metrics['pearson_corr']\n    overall_pcorr = np.array(overall_pcorr)\n    avg_pcorr = sum(overall_pcorr)/len(overall_pcorr)\n    sd_pcorr = np.std(overall_pcorr, axis=0, ddof=1)\n\n    overall_scorr = probability_metrics['spearman_corr']\n    overall_scorr = np.array(overall_scorr)\n    avg_scorr = sum(overall_scorr)/len(overall_scorr)\n    sd_scorr = np.std(overall_scorr, axis=0, ddof=1)\n\n    overall_mse = probability_metrics['mse']\n    overall_mse = np.array(overall_mse)\n    avg_mse = sum(overall_mse)/len(overall_mse)\n    sd_mse = np.std(overall_mse, axis=0, ddof=1)\n\n    overall_DICE = map_metrics['DICE']\n    overall_DICE = np.array(overall_DICE)\n    avg_DICE = sum(overall_DICE)/len(overall_DICE)\n    sd_DICE = np.std(overall_DICE, axis=0, ddof=1)\n\n    overall_HD = map_metrics['HD']\n    overall_HD = np.array(overall_HD)\n    avg_HD = sum(overall_HD)/len(overall_HD)\n    sd_HD = np.std(overall_HD, axis=0, ddof=1)\n\n    overall_jaccard = map_metrics['Jaccard']\n    overall_jaccard = np.array(overall_jaccard)\n    avg_jaccard = sum(overall_jaccard)/len(overall_jaccard)\n    sd_jaccard = np.std(overall_jaccard, axis=0, ddof=1)\n\n    print('Probability-Based Metrics:')\n    print('Val Loss: {} | Pearson: {} SD: {} | Spearman: {} SD: {} | MSE: {} SD: {}'.format(val_net_loss, avg_pcorr, sd_pcorr, avg_scorr, sd_scorr, avg_mse, sd_mse))\n\n    print('Map-Based Metrics:')\n    print('DICE: {} SD: {} | HD: {} SD: {} | Jaccard: {} SD: {}'.format(avg_DICE, sd_DICE, avg_HD, sd_HD, avg_jaccard, sd_jaccard))\n\n    log_name = os.path.join(args.root, 'test_TABS.txt')\n    with open(log_name, \"a\") as log_file:\n        log_file.write('Pearson: {} SD: {} | Spearman: {} SD: {} | MSE: {} SD: {}'.format(avg_pcorr, sd_pcorr, avg_scorr, sd_scorr, avg_mse, sd_mse))\n        log_file.write('\\n')\n        log_file.write('DICE: {} SD: {} | HD: {} SD: {} | Jaccard: {} SD: {}'.format(avg_DICE, sd_DICE, avg_HD, sd_HD, avg_jaccard, sd_jaccard))\n        log_file.write('\\n')\n        log_file.write('pcorr')\n        log_file.write('%s\\n' % overall_pcorr)\n        log_file.write('scorr')\n        log_file.write('%s\\n' % overall_scorr)\n        log_file.write('MSE')\n        log_file.write('%s\\n' % overall_mse)\n        log_file.write('dice')\n        log_file.write('%s\\n' % overall_DICE)\n        log_file.write('jaccard')\n        log_file.write('%s\\n' % overall_jaccard)\n        log_file.write('hd')\n        log_file.write('%s\\n' % overall_HD)","metadata":{"execution":{"iopub.status.busy":"2023-05-10T06:22:20.174835Z","iopub.execute_input":"2023-05-10T06:22:20.175233Z","iopub.status.idle":"2023-05-10T06:22:21.115651Z","shell.execute_reply.started":"2023-05-10T06:22:20.175204Z","shell.execute_reply":"2023-05-10T06:22:21.114354Z"},"trusted":true},"execution_count":35,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","Cell \u001b[0;32mIn[35], line 53\u001b[0m\n\u001b[1;32m     51\u001b[0m target \u001b[38;5;241m=\u001b[39m mask[g]\n\u001b[1;32m     52\u001b[0m stacked_brain_map \u001b[38;5;241m=\u001b[39m stacked_brain_maps[g]\n\u001b[0;32m---> 53\u001b[0m metrics_maps \u001b[38;5;241m=\u001b[39m \u001b[43mtissue_wise_map_metrics\u001b[49m\u001b[43m(\u001b[49m\u001b[43misolated_image\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstacked_brain_map\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     54\u001b[0m metrics \u001b[38;5;241m=\u001b[39m  tissue_wise_probability_metrics(isolated_image, target, stacked_brain_map)\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m metric \u001b[38;5;129;01min\u001b[39;00m probability_metrics_list:\n","Cell \u001b[0;32mIn[32], line 26\u001b[0m, in \u001b[0;36mtissue_wise_map_metrics\u001b[0;34m(isolated_image, target, stacked_brain_map)\u001b[0m\n\u001b[1;32m     23\u001b[0m     necessary_tensors[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124miso_\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(i)] \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmul(necessary_tensors[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124miso_\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(i)], mask)\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# calc HD with the segmentation masks\u001b[39;00m\n\u001b[0;32m---> 26\u001b[0m h_dist \u001b[38;5;241m=\u001b[39m \u001b[43mhd\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnecessary_tensors\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43miso_\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetach\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnecessary_tensors\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mGT_\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetach\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m metrics[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHD\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(h_dist)\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# now make cropped 1d numpy arrays only containing mask values for within the brain for dice calculation\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/medpy/metric/binary.py:348\u001b[0m, in \u001b[0;36mhd\u001b[0;34m(result, reference, voxelspacing, connectivity)\u001b[0m\n\u001b[1;32m    306\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mhd\u001b[39m(result, reference, voxelspacing\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, connectivity\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m    307\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    308\u001b[0m \u001b[38;5;124;03m    Hausdorff Distance.\u001b[39;00m\n\u001b[1;32m    309\u001b[0m \u001b[38;5;124;03m    \u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;124;03m    This is a real metric. The binary images can therefore be supplied in any order.\u001b[39;00m\n\u001b[1;32m    347\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 348\u001b[0m     hd1 \u001b[38;5;241m=\u001b[39m \u001b[43m__surface_distances\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreference\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvoxelspacing\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconnectivity\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mmax()\n\u001b[1;32m    349\u001b[0m     hd2 \u001b[38;5;241m=\u001b[39m __surface_distances(reference, result, voxelspacing, connectivity)\u001b[38;5;241m.\u001b[39mmax()\n\u001b[1;32m    350\u001b[0m     hd \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(hd1, hd2)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/medpy/metric/binary.py:1215\u001b[0m, in \u001b[0;36m__surface_distances\u001b[0;34m(result, reference, voxelspacing, connectivity)\u001b[0m\n\u001b[1;32m   1213\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThe first supplied array does not contain any binary object.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m   1214\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;241m0\u001b[39m \u001b[38;5;241m==\u001b[39m numpy\u001b[38;5;241m.\u001b[39mcount_nonzero(reference): \n\u001b[0;32m-> 1215\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThe second supplied array does not contain any binary object.\u001b[39m\u001b[38;5;124m'\u001b[39m)    \n\u001b[1;32m   1217\u001b[0m \u001b[38;5;66;03m# extract only 1-pixel border line of objects\u001b[39;00m\n\u001b[1;32m   1218\u001b[0m result_border \u001b[38;5;241m=\u001b[39m result \u001b[38;5;241m^\u001b[39m binary_erosion(result, structure\u001b[38;5;241m=\u001b[39mfootprint, iterations\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n","\u001b[0;31mRuntimeError\u001b[0m: The second supplied array does not contain any binary object."],"ename":"RuntimeError","evalue":"The second supplied array does not contain any binary object.","output_type":"error"}]}]}